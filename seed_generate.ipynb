{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105147/3842362895.py:13: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  disaster_data = pd.read_csv('./data/emdat_public_2022_01_31.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from sklearn.impute import KNNImputer\n",
    "from countryinfo import CountryInfo\n",
    "import pycountry_convert as pc\n",
    "import warnings\n",
    "import json\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "with open('keys.json') as json_file:\n",
    "    column_keys = json.load(json_file)\n",
    "data = pd.read_csv('./data/HNP_StatsData.csv')\n",
    "countries_info = pd.read_csv('./data/HNP_StatsCountry.csv')\n",
    "disaster_data = pd.read_csv('./data/emdat_public_2022_01_31.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "  'CAN',\n",
    "  'USA',\n",
    "  'MEX',\n",
    "  'IND',\n",
    "  'CHN',\n",
    "  'SDN',\n",
    "  'BGD',\n",
    "  'BRA',\n",
    "  'NER'\n",
    "]\n",
    "countries_full = [\n",
    "  'Canada',\n",
    "  'United States of America (the)',\n",
    "  'Mexico',\n",
    "  'India',\n",
    "  'China',\n",
    "  'Sudan',\n",
    "  'Bangladesh',\n",
    "  'Brazil',\n",
    "  'Niger'\n",
    "]\n",
    "\n",
    "education_keys = [\n",
    "  'SE.ADT.LITR.ZS',\n",
    "  'SE.ADT.LITR.FE.ZS',\n",
    "  'SE.ADT.LITR.MA.ZS',\n",
    "  'SE.PRM.ENRR',\n",
    "  'SE.PRM.ENRR.FE',\n",
    "  'SE.PRM.ENRR.MA',\n",
    "  'SE.SEC.ENRR',\n",
    "  'SE.SEC.ENRR.FE',\n",
    "  'SE.SEC.ENRR.MA',\n",
    "  'SE.XPD.TOTL.GD.ZS',\n",
    "  'SE.TER.ENRR',\n",
    "  'SE.PRM.CMPT.ZS'\n",
    "]\n",
    "\n",
    "health_keys = [\n",
    "  'SH.DTH.COMM.ZS',\n",
    "  'SH.DTH.NCOM.ZS',\n",
    "  'SH.XPD.CHEX.GD.ZS',\n",
    "  'SH.MED.BEDS.ZS',\n",
    "  'SH.IMM.MEAS',\n",
    "  'SH.STA.OWGH.ME.ZS',\n",
    "  'SH.STA.OWGH.ME.ZS',\n",
    "  'SH.TBS.INCD',\n",
    "  'SH.ANM.CHLD.ZS',\n",
    "  'SH.IMM.POL3',\n",
    "  'SH.IMM.IDPT',\n",
    "  'SH.STA.DIAB.ZS',\n",
    "  'SH.UHC.SRVS.CV.XD',\n",
    "  'SH.MED.NUMW.P3'\n",
    "]\n",
    "\n",
    "quality_of_life_keys = [\n",
    "  'SH.STA.BASS.ZS',\n",
    "  'SH.STA.SMSS.ZS',\n",
    "  'SH.STA.WASH.P5',\n",
    "  'SH.H2O.BASW.ZS',\n",
    "  'SH.H2O.SMDW.ZS',\n",
    "  'SL.TLF.TOTL.IN',\n",
    "  'SL.UEM.TOTL.MA.ZS',\n",
    "  'SL.UEM.TOTL.FE.ZS',\n",
    "  'SH.MMR.WAGE.ZS',\n",
    "  'SI.POV.NAHC',\n",
    "  'SH.STA.ODFC.ZS',\n",
    "  'SL.TLF.TOTL.FE.ZS',\n",
    "  'SH.STA.AIRP.P5',\n",
    "  'SH.STA.BRTC.ZS ',\n",
    "]\n",
    "\n",
    "population_keys = [\n",
    "  'SP.POP.TOTL',\n",
    "  'SP.DYN.LE00.MA.IN',\n",
    "  'SP.DYN.LE00.FE.IN ',\n",
    "  'SP.POP.GROW ',\n",
    "  'SP.DYN.LE00.IN',\n",
    "  'SM.POP.NETM',\n",
    "  'SP.RUR.TOTL',\n",
    "  'SP.RUR.TOTL.ZG',\n",
    "  'SI.POV.RUHC',\n",
    "  'SP.URB.TOTL',\n",
    "  'SP.URB.GROW',\n",
    "  'SI.POV.URHC',\n",
    "  'SP.POP.TOTL.MA.ZS',\n",
    "  'SP.POP.TOTL.FE.ZS'\n",
    "]\n",
    "\n",
    "columns = [\n",
    "  'Country Name',\n",
    "  'Country Code',\n",
    "  'Indicator Name',\n",
    "  'Indicator Code',\n",
    "  '2005',\n",
    "  '2006',\n",
    "  '2007',\n",
    "  '2008',\n",
    "  '2009',\n",
    "  '2010',\n",
    "  '2011',\n",
    "  '2012',\n",
    "  '2013',\n",
    "  '2014',\n",
    "  '2015',\n",
    "  '2016',\n",
    "  '2017',\n",
    "  '2018',\n",
    "  '2019',\n",
    "  '2020'\n",
    "]\n",
    "\n",
    "country_columns = [\n",
    "  \"Long Name\",\n",
    "  \"Short Name\",\n",
    "  \"Country Code\",\n",
    "  \"Region\",\n",
    "  # Continent\n",
    "  \"Currency Unit\",\n",
    "  # Capital\n",
    "  # Number of languages\n",
    "  # area\n",
    "  \"Income Group\",\n",
    "  \"Latest population census\"  \n",
    "]\n",
    "disaster_columns = [\n",
    "  'Dis No',\n",
    "  'Country',\n",
    "  'Start Year',\n",
    "  'Start Month',\n",
    "  'Start Day',\n",
    "  'End Year',\n",
    "  'End Month',\n",
    "  'End Day',\n",
    "  'Disaster Group',\n",
    "  'Disaster Subgroup',\n",
    "  'Disaster Type',\n",
    "  'Disaster Subtype',\n",
    "  'Total Affected',\n",
    "  'Total Deaths',  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Seed Data for World Bank Data\n",
    "This code block generates csv files to be used to populate the Data Mart with data directly fetched from the wolrd bank source file, namely Education, Health, Population, and Quality of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(columns, keys, countries, tableName):\n",
    "  selected_data = pd.DataFrame()\n",
    "  selected_data_imputed = pd.DataFrame()\n",
    "  for country in countries:\n",
    "    current_info = data.loc[data['Country Code'] == country]\n",
    "    current_info = current_info.loc[data['Indicator Code'].isin(keys)]\n",
    "    current_info = current_info[columns]\n",
    "    cols = current_info.columns.tolist()\n",
    "    # convert Year into its own column\n",
    "    current_info = current_info.melt(id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'], var_name= \"Year\", value_name=\"Value\")\n",
    "    cols = current_info.columns.tolist()\n",
    "    cols.insert(2, cols.pop(cols.index(\"Year\")))\n",
    "    current_info = current_info.reindex(columns= cols) #Reposition the Year column into index 2\n",
    "    current_info = current_info.drop('Indicator Code', 1) #Drop the Indicator Code column\n",
    "    current_info = current_info.pivot_table('Value', ['Country Name', 'Country Code', 'Year'], 'Indicator Name').reset_index() #Pivot the table so that Each value in indicator Name is its own column\n",
    "    cols = current_info.columns.tolist()\n",
    "    numeric_info = current_info.iloc[:,3:]\n",
    "    imputer = KNNImputer()\n",
    "    imputer.fit(numeric_info)\n",
    "    sample_incomplete_rows = numeric_info[numeric_info.isnull().any(axis=1)].head()\n",
    "    input_x = imputer.transform(numeric_info)\n",
    "    imputed_data = pd.DataFrame(input_x, columns=numeric_info.columns, index=numeric_info.index)\n",
    "    result = pd.concat([current_info.iloc[:,:3], imputed_data], axis=1, join=\"inner\")\n",
    "    selected_data_imputed = pd.concat((selected_data_imputed, result[cols]))\n",
    "    selected_data = pd.concat((selected_data, current_info))\n",
    "  selected_data_imputed.insert(0, 'key', [i for i in range(len(selected_data_imputed.index))])\n",
    "  selected_data.insert(0, 'key', [i for i in range(len(selected_data.index))])\n",
    "  # print(selected_data_imputed.head())\n",
    "  selected_data_imputed = selected_data_imputed.rename(columns=column_keys)\n",
    "  selected_data_imputed.to_csv(path_or_buf=f'./seed_data/{tableName}_seed.csv', index=False)\n",
    "  # selected_data.to_csv(path_or_buf=f'./seed_data/{tableName}_Unimputed.csv', columns=cols, index=False)\n",
    "tables = {\n",
    "  'Education': education_keys,\n",
    "  'Health' : health_keys,\n",
    "  'Quality_of_life' : quality_of_life_keys,\n",
    "  'Population': population_keys\n",
    "  }\n",
    "for key in tables:\n",
    "  getData(columns, tables[key], countries, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Seed Data for Countries\n",
    "This Code block generates the csv files used to populate Country table in the data mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pd.DataFrame()\n",
    "for country in countries:\n",
    "  current_info = countries_info.loc[countries_info['Country Code'] == country][country_columns]\n",
    "  alpha =countries_info.loc[countries_info['Country Code'] == country][\"2-alpha code\"].values[0]\n",
    "  continent = pc.country_alpha2_to_continent_code(alpha)\n",
    "  current_countryInfo = CountryInfo(alpha)\n",
    "  capital = current_countryInfo.capital()\n",
    "  area = current_countryInfo.area()\n",
    "  numLanguages = len(current_countryInfo.languages())\n",
    "  current_info.insert(len(current_info.columns),'continent', continent)\n",
    "  current_info.insert(len(current_info.columns),'capital', capital)\n",
    "  current_info.insert(len(current_info.columns),'area', area)\n",
    "  current_info.insert(len(current_info.columns),'num_languages', numLanguages)\n",
    "  selected_data = pd.concat((selected_data, current_info))\n",
    "\n",
    "selected_data.insert(0, 'key', [i for i in range(len(selected_data.index))])\n",
    "selected_data.to_csv(path_or_buf=f'./seed_data/countries_seed.csv', columns=selected_data.columns, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Seed Data for Events\n",
    "The events table includes data from two sources, one source includes infromation on disasters, natural and otherwise, the other includes informaiton on terrorist attacks. The information from these two data sources has been conformed to fit into the event dimension and the CSV file to populate this dimension is generated using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key Country  start_year  start_month  start_day  end_year  end_month  \\\n",
      "14009    0  Canada        2005          9.0       27.0      2005        9.0   \n",
      "14010    1  Canada        2005          6.0        7.0      2005        7.0   \n",
      "14013    2  Canada        2005         11.0       30.0      2005       12.0   \n",
      "14014    3  Canada        2005          5.0        8.0      2005        5.0   \n",
      "14015    4  Canada        2005          9.0       26.0      2005        9.0   \n",
      "\n",
      "       end_day disaster_group disaster_subgroup  ...  \\\n",
      "14009     29.0        Natural      Hydrological  ...   \n",
      "14010      1.0        Natural      Hydrological  ...   \n",
      "14013      1.0  Technological     Technological  ...   \n",
      "14014      8.0  Technological     Technological  ...   \n",
      "14015     29.0        Natural    Meteorological  ...   \n",
      "\n",
      "      Reconstruction Costs, Adjusted ('000 US$) Insured Damages ('000 US$)  \\\n",
      "14009                                       NaN                        NaN   \n",
      "14010                                       NaN                   186000.0   \n",
      "14013                                       NaN                        NaN   \n",
      "14014                                       NaN                        NaN   \n",
      "14015                                       NaN                        NaN   \n",
      "\n",
      "       Insured Damages, Adjusted ('000 US$)  Total Damages ('000 US$)  \\\n",
      "14009                                   NaN                       NaN   \n",
      "14010                              246497.0                  357000.0   \n",
      "14013                                   NaN                       NaN   \n",
      "14014                                   NaN                       NaN   \n",
      "14015                                   NaN                       NaN   \n",
      "\n",
      "       Total Damages, Adjusted ('000 US$)      CPI Adm Level Admin1 Code  \\\n",
      "14009                                 NaN  75.4572         2         NaN   \n",
      "14010                            473116.0  75.4572         2         NaN   \n",
      "14013                                 NaN  75.4572       NaN         NaN   \n",
      "14014                                 NaN  75.4572       NaN         NaN   \n",
      "14015                                 NaN  75.4572         2         NaN   \n",
      "\n",
      "                                             Admin2 Code  \\\n",
      "14009                                        12611;12612   \n",
      "14010                      12521;12522;12524;12525;12527   \n",
      "14013                                                NaN   \n",
      "14014                                                NaN   \n",
      "14015  12695;12699;12703;12706;12707;12710;12713;1273...   \n",
      "\n",
      "                                           Geo Locations  \n",
      "14009             Division No. 4, Division No. 5 (Adm2).  \n",
      "14010  Division No. 2, Division No. 3, Division No. 5...  \n",
      "14013                                                NaN  \n",
      "14014                                                NaN  \n",
      "14015  Acton, Beauharnois-Salaberry, Brome-Missisquoi...  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "selected_data = pd.DataFrame(columns = disaster_columns)\n",
    "for country in countries_full:\n",
    "    current_info = disaster_data.loc[disaster_data['Country'] == country]\n",
    "    current_info = current_info.loc[disaster_data['Start Year'].between(2005, 2020)]\n",
    "    selected_data = selected_data.append(current_info)\n",
    "# selected_data['Total Deaths'] = np.where((selected_data['Total Affected'] > 0) &  (selected_data['Total Deaths'].isna()), 0 , \"\" )\n",
    "#Fills in missing values in Total affected and Total deaths based off assumptions.\n",
    "selected_data.loc [(selected_data['Total Affected'] > 0) & (selected_data['Total Deaths'].isnull()), 'Total Deaths'] = 0\n",
    "selected_data.loc [(selected_data['Total Affected'].isnull()) & (selected_data['Total Deaths'].isnull()), 'Total Deaths'] = 0 \n",
    "selected_data.loc [(selected_data['Total Affected'].isnull()) & (selected_data['Total Deaths'].notnull()), 'Total Affected'] = selected_data['Total Deaths']\n",
    "selected_data.loc [(selected_data['Disaster Subtype'].isnull()), 'Disaster Subtype'] = \"None\"\n",
    "selected_data = selected_data.replace('United States of America (the)','United States of America')\n",
    "\n",
    "#Deletes columns with missing data in Start day\n",
    "indexs = selected_data[selected_data['Start Day'].isnull()].index\n",
    "selected_data.drop(indexs, inplace=True)\n",
    "selected_data = selected_data.rename(columns=column_keys)\n",
    "#\n",
    "# Add Lilian's code to get  terrorist attacks here, and add to dataframe!\n",
    "#\n",
    "selected_data = selected_data.drop(columns=['key'])\n",
    "selected_data.insert(0, 'key', [i for i in range(len(selected_data.index))])\n",
    "print(selected_data.head())\n",
    "\n",
    "selected_data.to_csv(path_or_buf=f'./seed_data/Events_seed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Seed Data\n",
    "Here entries for the  date table are generated, this is simply done by looping through 12 months for each year in the perisod spedified in the project outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\n",
    "  'January',\n",
    "  'February',\n",
    "  'March',\n",
    "  'April',\n",
    "  'May',\n",
    "  'June',\n",
    "  'July',\n",
    "  'August',\n",
    "  'September',\n",
    "  'October',\n",
    "  'November',\n",
    "  'December'\n",
    "]\n",
    "df = pd.DataFrame(columns=['key', 'name', 'year', 'month_number', 'quarter', 'decade'])\n",
    "key = 0\n",
    "for year in range(2005, 2021):\n",
    "  for month in range(12):\n",
    "    df = df.append({\n",
    "      'key': key,\n",
    "      'name': months[month],\n",
    "      'year': year,\n",
    "      'month_number': month,\n",
    "      'quarter': month//3,\n",
    "      'decade': year//10,\n",
    "    }, ignore_index=True)\n",
    "    key +=1\n",
    "\n",
    "df.to_csv(path_or_buf=f'./seed_data/date_seed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Table Generate\n",
    "\n",
    "Here, the entries for the fact table are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.read_csv('./seed_data/date_seed.csv')\n",
    "events = pd.read_csv('./seed_data/Events_seed.csv')\n",
    "education = pd.read_csv('./seed_data/Education_seed.csv')\n",
    "health = pd.read_csv('./seed_data/Health_seed.csv')\n",
    "population = pd.read_csv('./seed_data/Population_seed.csv')\n",
    "qualityOfLife = pd.read_csv('./seed_data/Quality_of_life_seed.csv')\n",
    "countries = pd.read_csv('./seed_data/countries_seed.csv')\n",
    "\n",
    "fact_columns = [\n",
    "  'index',\n",
    "  'country_key',\n",
    "  'date_key',\n",
    "  'education_key',\n",
    "  'health_key',\n",
    "  'quality_of_life_key',\n",
    "  'event_key',\n",
    "]\n",
    "\n",
    "def extractKey(key):\n",
    "  if len(key) ==0:\n",
    "    return None\n",
    "  else:\n",
    "    return key[0]\n",
    "\n",
    "def checkDate(start_year, start_month, end_year, end_month, current_year, current_month):\n",
    "  if start_year == end_year == current_year:\n",
    "    if current_month >= start_month and current_month <= end_month:\n",
    "      return True\n",
    "  elif start_year == current_year:\n",
    "    if current_month >= start_month:\n",
    "      return True\n",
    "  elif end_year == current_year:\n",
    "    if current_month <= end_month:\n",
    "      return True\n",
    "  elif current_year > start_year and current_year < end_year:\n",
    "    return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  country_key  date_key  education_key  health_key  \\\n",
      "0      0            2         1             32          32   \n",
      "0      1            3         1             48          48   \n",
      "0      2            3         1             48          48   \n",
      "0      3            4         1             64          64   \n",
      "0      4            4         1             64          64   \n",
      "\n",
      "   quality_of_life_key  event_key  \n",
      "0                   32        458  \n",
      "0                   48        628  \n",
      "0                   48        630  \n",
      "0                   64       1115  \n",
      "0                   64       1117  \n",
      "['index', 'country_key', 'date_key', 'education_key', 'health_key', 'quality_of_life_key', 'event_key']\n"
     ]
    }
   ],
   "source": [
    "facts = pd.DataFrame( )\n",
    "index = 0\n",
    "for date_index in dates.index:\n",
    "  for country_index in countries.index:\n",
    "    country_code = countries['Country Code'][country_index]\n",
    "    country_name = countries['Short Name'][country_index]\n",
    "    year = dates['year'][date_index]\n",
    "    month = dates['month_number'][date_index]\n",
    "    education_key = extractKey(education[(education['alpha_code']==country_code) & (education['Year']==year)]['key'].values)\n",
    "    health_key = extractKey(health[(health['alpha_code']==country_code) & (health['Year']==year)]['key'].values)\n",
    "    quality_of_life_key = extractKey(qualityOfLife[(qualityOfLife['alpha_code']==country_code) & (qualityOfLife['Year']==year)]['key'].values)\n",
    "    population_key = extractKey(population[(population['alpha_code']==country_code) & (population['Year']==year)]['key'].values)\n",
    "    # print(country_name)\n",
    "    country_events = events[events['Country']==country_name]\n",
    "    current_events = []\n",
    "    for event_index in country_events.index:\n",
    "      if checkDate(country_events['start_year'][event_index],country_events['start_month'][event_index],country_events['end_year'][event_index],country_events['end_month'][event_index], year, month):\n",
    "        current_events.append(country_events['key'][event_index])\n",
    "    for event_key in current_events:\n",
    "      facts = facts.append(pd.DataFrame([[index, country_index, date_index,education_key, health_key,quality_of_life_key,event_key]], columns=fact_columns))\n",
    "      index += 1\n",
    "print(facts.head())\n",
    "print(fact_columns)\n",
    "facts.to_csv(path_or_buf=f'./seed_data/Facts.csv', index=False) \n",
    "      #   selected_data_imputed.insert(0, 'key', [i for i in range(len(selected_data_imputed.index))])\n",
    "\n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "367e97bd1bb993270875333a5c0c0ed703268d8b20e00e99d22f213f8fc7c5a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
